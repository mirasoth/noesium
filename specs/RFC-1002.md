# RFC-1002: LangGraph-Based Agent Implementation Design

**Status**: Draft
**Authors**: Noesium Team
**Created**: 2026-03-01
**Last Updated**: 2026-03-01
**Depends on**: [RFC-0003](RFC-0003.md), [RFC-0005](RFC-0005.md), [RFC-1001](RFC-1001.md)
**Supersedes**: ---
**Kind**: Implementation Interface Design

---

## 1. Abstract

This RFC defines the implementation design for LangGraph-based agents in Noesium. It specifies how the deterministic kernel execution model (RFC-0003) and capability registry (RFC-0005) are realized through concrete LangGraph patterns. The RFC defines three agent archetypes — Conversation, Research, and Task — along with their state models, graph construction patterns, node execution contracts, human-in-the-loop workflows, checkpointing strategies, and lifecycle management. This RFC builds on the core infrastructure defined in RFC-1001 and provides the implementation contract for all Noesium agents.

---

## 2. Scope and Non-Goals

### 2.1 Scope

This RFC defines:

* Agent archetypes and their inheritance hierarchy
* LangGraph `StateGraph` construction patterns and conventions
* State model design patterns (TypedDict vs Pydantic, reducers, annotations)
* Node execution contracts (input/output shapes, side-effect boundaries)
* Conditional routing and branching patterns
* Parallel execution via `Send` and fan-out/fan-in patterns
* Human-in-the-loop (HITL) interrupt and resume patterns
* Checkpointing and persistence strategies
* Agent lifecycle: initialization, execution, teardown
* Configuration and extensibility patterns
* Integration with RFC-1001 kernel executor and event system

### 2.2 Non-Goals

This RFC does **not** define:

* Core infrastructure (event system, projection layer, capability registry) — see [RFC-1001](RFC-1001.md)
* Individual toolkit implementations
* LLM prompt engineering or prompt templates
* Deployment, scaling, or multi-process distribution
* Browser automation agent specifics

---

## 3. Background & Motivation

Noesium agents are implemented as LangGraph `StateGraph` workflows. The current codebase contains three distinct agent patterns:

1. **AskuraAgent** — A conversation agent using `BaseHitlAgent` with HITL interrupts, session management, and in-memory checkpointing
2. **SearchAgent** — A task-oriented agent using `BaseGraphicAgent` with linear graph flow and optional conditional branches
3. **DeepResearchAgent** — A research agent using `BaseResearcher` with iterative loops, parallel `Send` dispatching, and structured LLM output

Each agent follows a different pattern for state management, graph construction, and node design. This RFC standardizes these patterns into formal archetypes while preserving the flexibility that makes each agent effective.

The motivation is to:

1. Establish consistent patterns that new agents can follow
2. Define node execution contracts aligned with RFC-0003 determinism goals
3. Formalize state management to enable event-sourced projection (RFC-1001)
4. Standardize HITL patterns across conversation agents
5. Provide clear extension points for custom agents

---

## 4. Design Principles

1. **Graph as Contract**: The `StateGraph` definition is the authoritative specification of an agent's behavior. All execution paths MUST be declared in the graph.
2. **State as Single Source of Truth**: All agent state lives in the graph state object. No hidden mutable state outside the graph.
3. **Nodes as Pure Transformers**: Graph nodes SHOULD be pure functions of `(state) → state_delta`. Non-deterministic operations (LLM calls, tool invocations) MUST be explicitly marked.
4. **Explicit Routing**: All branching MUST be implemented via `add_conditional_edges` with named targets. Implicit routing is prohibited.
5. **Composable Archetypes**: Agent archetypes provide reusable patterns; concrete agents extend them with domain-specific logic.

---

## 5. Agent Archetypes

### 5.1 Archetype Hierarchy

```
BaseAgent (ABC)
│
├── BaseGraphicAgent(BaseAgent)
│   │   StateGraph, KernelExecutor, capability declaration
│   │
│   ├── BaseHitlAgent(BaseGraphicAgent)
│   │       Session management, HITL, checkpointing
│   │       Archetype: Conversation Agent
│   │
│   ├── BaseResearcher(BaseGraphicAgent)
│   │       Iterative research loops, source management, citations
│   │       Archetype: Research Agent
│   │
│   └── [Direct subclass]
│           Linear or branching task workflows
│           Archetype: Task Agent
```

### 5.2 Conversation Agent Archetype

**Purpose**: Multi-turn human-in-the-loop conversations with session persistence.

**Characteristics**:

| Property | Value |
|----------|-------|
| Base class | `BaseHitlAgent` |
| State model | Pydantic `BaseModel` |
| Checkpointing | Required (`InMemorySaver` or persistent) |
| HITL | `interrupt_before` on review nodes |
| Session scope | Per-user, per-session state isolation |
| Execution | Synchronous `invoke()` |

**Reference graph topology** (AskuraAgent):

```
START → context_analysis → message_dispatcher
    ├─[deep_thinking]→ start_deep_thinking ──┬→ information_extractor ──┐
    │                                         └→ memory_retrival ───────┤
    │                                                                    ↓
    │                                                              reflection
    │                                                             ┌────┴────┐
    │                                                     memory_retention  next_action
    │                                                                      ┌────┴────┐
    ├─[response]→ response_generator → human_review ←──────────────────────┘         │
    │                                      │                                    summarizer
    │                                      ├─[continue]→ context_analysis           │
    └─[end]→ END ←─────────────────────────┴─[end]→ END ←──────────────────────────┘
```

**Key patterns**:

* `interrupt_before=["human_review"]` pauses execution for user input
* `InMemorySaver` enables resume from checkpoint via `thread_id`
* Session state stored in `_session_states` dict keyed by session ID
* Messages accumulated via LangGraph `add_messages` reducer

---

### 5.3 Research Agent Archetype

**Purpose**: Iterative, multi-step research with parallel query execution and reflection loops.

**Characteristics**:

| Property | Value |
|----------|-------|
| Base class | `BaseResearcher` |
| State model | `TypedDict` with `Annotated` reducers |
| Checkpointing | Optional |
| HITL | Not required |
| Parallel execution | `Send` for fan-out to worker nodes |
| Loop control | Reflection-based iteration with max bounds |
| Execution | Async `ainvoke()` |

**Reference graph topology** (DeepResearchAgent):

```
START → generate_query ──[Send per query]──→ web_research ──→ reflection
                                                                  │
                                                    ┌─[sufficient]┴─[insufficient]─┐
                                                    ↓                               ↓
                                             finalize_answer              [Send follow-ups]
                                                    │                         → web_research
                                                   END
```

**Key patterns**:

* `Send("web_research", WebSearchState(...))` dispatches parallel worker executions
* `Annotated[list, operator.add]` reducers merge parallel results
* Reflection node evaluates completeness and decides loop continuation
* `max_research_loops` bounds iteration to prevent infinite loops
* Multiple `TypedDict` state classes for different graph phases (`QueryState`, `WebSearchState`, `ReflectionState`)

---

### 5.4 Task Agent Archetype

**Purpose**: Linear or branching task execution with optional conditional steps.

**Characteristics**:

| Property | Value |
|----------|-------|
| Base class | `BaseGraphicAgent` (direct) |
| State model | `TypedDict` |
| Checkpointing | Optional |
| HITL | Not required |
| Parallel execution | Not typical |
| Execution | Async `ainvoke()` |

**Reference graph topology** (SearchAgent):

```
START → polish_query → web_search → crawl_web
                                       │
                              ┌─[rerank]┴─[skip]─┐
                              ↓                   ↓
                         rank_results      finalize_search
                              │                   │
                              └→ finalize_search ←┘
                                       │
                                      END
```

**Key patterns**:

* Linear pipeline with optional conditional branches
* Conditional routing based on configuration flags (e.g., `enable_reranking`)
* State passed through and mutated by each node
* No iteration loops

---

## 6. State Model Design

### 6.1 State Model Options

Noesium supports two state model approaches:

| Approach | Use Case | Pros | Cons |
|----------|----------|------|------|
| `TypedDict` | Research, Task agents | Native LangGraph support, reducer annotations | No validation, no defaults |
| Pydantic `BaseModel` | Conversation agents | Validation, defaults, serialization | Requires dict conversion at graph boundaries |

### 6.2 State Design Rules

**MUST**:

* All agent state MUST be contained in the graph state object
* State fields that accumulate across nodes MUST use reducer annotations
* State MUST be serializable to JSON for checkpointing and event emission

**SHOULD**:

* State fields SHOULD have clear ownership (which node writes to which field)
* Conversation history SHOULD use `Annotated[list, add_messages]` reducer
* Accumulated collections SHOULD use `Annotated[list, operator.add]` reducer

**MUST NOT**:

* Nodes MUST NOT store state in instance variables that bypass the graph state
* Nodes MUST NOT mutate state fields they do not own

### 6.3 Standard State Fields

All agent states SHOULD include these common fields:

```python
class AgentStateBase(TypedDict):
    messages: Annotated[list, add_messages]
```

Conversation agents extend with session metadata:

```python
class ConversationStateBase(BaseModel):
    user_id: str = ""
    session_id: str = ""
    turns: int = 0
    created_at: str = ""
    updated_at: str = ""
    messages: Sequence[BaseMessage] = Field(default_factory=list)
    is_complete: bool = False
    requires_user_input: bool = True
```

Research agents extend with accumulation fields:

```python
class ResearchStateBase(TypedDict):
    messages: Annotated[list, add_messages]
    search_query: Annotated[list, operator.add]
    sources_gathered: Annotated[list, operator.add]
    research_loop_count: int
    max_research_loops: int
```

### 6.4 Phase-Specific State Types

Research agents MAY define separate state types for different graph phases:

```python
class QueryState(TypedDict):
    """Emitted by query generation, consumed by Send routing."""
    query_list: list[dict]

class WebSearchState(TypedDict):
    """Input to parallel web_research worker nodes."""
    search_query: str
    id: str
```

Phase-specific states are used with `Send()` to dispatch focused payloads to worker nodes without carrying the full agent state.

---

## 7. Graph Construction Patterns

### 7.1 Graph Building Contract

All agents MUST implement `_build_graph()` returning a compiled `StateGraph`:

```python
class MyAgent(BaseGraphicAgent):
    @override
    def _build_graph(self) -> StateGraph:
        state_class = self.get_state_class()
        workflow = StateGraph(state_class)

        # 1. Add nodes
        workflow.add_node("step_a", self._step_a_node)
        workflow.add_node("step_b", self._step_b_node)

        # 2. Define edges
        workflow.add_edge(START, "step_a")
        workflow.add_edge("step_a", "step_b")
        workflow.add_edge("step_b", END)

        # 3. Compile with optional checkpointer
        return workflow.compile()
```

### 7.2 Node Naming Conventions

| Pattern | Example | Use Case |
|---------|---------|----------|
| `{verb}_{noun}` | `generate_query`, `polish_query` | Action nodes |
| `{noun}_{verb}er` | `context_analysis`, `information_extractor` | Processing nodes |
| `{noun}_node` suffix | `_reflection_node`, `_finalize_answer_node` | Method names (private) |

Node method names MUST be prefixed with `_` and suffixed with `_node`:

```python
def _reflection_node(self, state: MyState, config: RunnableConfig) -> dict: ...
```

### 7.3 Conditional Edge Patterns

**Binary routing** (two targets):

```python
workflow.add_conditional_edges(
    "evaluate",
    self._evaluate_router,
    {"continue": "next_step", "finish": "finalize"},
)
```

**Multi-target routing** with string return:

```python
def _evaluate_router(self, state: MyState) -> str:
    if state["is_complete"]:
        return "finalize"
    return "continue"
```

**Fan-out routing** with `Send`:

```python
def _fan_out_router(self, state: QueryState) -> list[Send]:
    return [
        Send("worker_node", WorkerState(query=q["query"], id=str(i)))
        for i, q in enumerate(state["query_list"])
    ]
```

### 7.4 Compilation Options

| Option | Use Case |
|--------|----------|
| `compile()` | Basic compilation, no persistence |
| `compile(checkpointer=saver)` | Enable checkpointing for resume |
| `compile(checkpointer=saver, interrupt_before=["node"])` | HITL with checkpoint |

---

## 8. Node Execution Contract

### 8.1 Node Signature

All graph nodes MUST follow one of these signatures:

```python
# Sync node
def _my_node(self, state: StateType, config: RunnableConfig) -> dict | StateType:
    ...

# Async node
async def _my_node(self, state: StateType, config: RunnableConfig) -> dict | StateType:
    ...
```

### 8.2 Return Value Contract

Nodes return either:

1. **State delta dict** — Partial state update merged into the current state:

```python
def _my_node(self, state: ResearchState, config: RunnableConfig) -> dict:
    return {"search_query": [new_query], "research_loop_count": state["research_loop_count"] + 1}
```

2. **Full state object** — Replaces the current state (Pydantic models):

```python
def _my_node(self, state: AskuraState, config: RunnableConfig) -> AskuraState:
    state.turns += 1
    return state
```

3. **None or empty dict** — No state change (pass-through nodes):

```python
def _start_node(self, state: MyState, config: RunnableConfig) -> dict:
    return {}
```

### 8.3 Node Classification

| Classification | Deterministic | Side Effects | Examples |
|----------------|---------------|--------------|----------|
| Pure transformer | Yes | None | State merging, filtering, formatting |
| LLM-backed | No | LLM API call | Query generation, reflection, response generation |
| Tool-backed | No | External IO | Web search, file read, API calls |
| Pass-through | Yes | None | Dispatcher, start markers |
| Routing | Yes | None | Conditional edge evaluation functions |

For integration with the kernel executor (RFC-1001), nodes SHOULD be annotated:

```python
@kernel_node(deterministic=False, entropy_sources=["llm"])
async def _generate_query_node(self, state: ResearchState, config: RunnableConfig) -> dict:
    ...
```

### 8.4 Event Emission from Nodes

In pragmatic mode, nodes emit events by appending to a reserved state field:

```python
def _my_node(self, state: MyState, config: RunnableConfig) -> dict:
    return {
        "field": new_value,
        "_pending_events": [NodeCompleted(node_id="my_node", ...)],
    }
```

The kernel executor collects and publishes `_pending_events` after node completion.

---

## 9. Human-in-the-Loop Patterns

### 9.1 Interrupt and Resume

HITL is implemented via LangGraph's `interrupt_before` mechanism:

```python
graph = workflow.compile(
    checkpointer=InMemorySaver(),
    interrupt_before=["human_review"],
)
```

**Execution flow**:

1. Graph executes until reaching `human_review` node
2. Execution pauses; state is checkpointed
3. External code retrieves response from last AI message
4. User provides input
5. User input is appended to state messages
6. Graph resumes from checkpoint via `thread_id`

### 9.2 Session Management Pattern

```python
class MyConversationAgent(BaseHitlAgent):
    def start_conversation(self, user_id: str, initial_message: str) -> Response:
        session_id = str(uuid.uuid4())
        state = MyState(user_id=user_id, session_id=session_id, ...)

        if initial_message:
            state.messages = add_messages(state.messages, [HumanMessage(content=initial_message)])

        self._session_states[session_id] = state
        response, updated_state = self._run_graph(state)
        self._session_states[session_id] = updated_state
        return response

    def process_user_message(self, user_id: str, session_id: str, message: str) -> Response:
        state = self._session_states[session_id]
        state.messages = add_messages(state.messages, [HumanMessage(content=message)])
        response, updated_state = self._run_graph(state)
        self._session_states[session_id] = updated_state
        return response
```

### 9.3 Checkpoint Configuration

```python
config = RunnableConfig(
    configurable={"thread_id": session_id},
    recursion_limit=max_turns,
    callbacks=[NodeLoggingCallback(), TokenUsageCallback()],
)
result = self.graph.invoke(state, config)
```

---

## 10. Parallel Execution Patterns

### 10.1 Fan-Out with Send

For parallel task distribution, use `Send` in conditional edge functions:

```python
workflow.add_conditional_edges(
    "generate_query",
    self._dispatch_queries,
    ["web_research"],
)

def _dispatch_queries(self, state: QueryState) -> list[Send]:
    return [
        Send("web_research", WebSearchState(search_query=q["query"], id=str(i)))
        for i, q in enumerate(state["query_list"])
    ]
```

### 10.2 Fan-In with Reducers

Parallel results merge back via annotated reducers on the target state:

```python
class ResearchState(TypedDict):
    sources_gathered: Annotated[list, operator.add]  # Fan-in: all workers append
    search_summaries: Annotated[list, operator.add]
```

### 10.3 Iterative Fan-Out

For research loops, reflection nodes can emit follow-up `Send` dispatches:

```python
def _evaluate_research(self, state: ReflectionState, config: RunnableConfig):
    if state["is_sufficient"] or state["research_loop_count"] >= self.max_research_loops:
        return "finalize_answer"
    return [
        Send("web_research", WebSearchState(search_query=q, id=str(offset + i)))
        for i, q in enumerate(state["follow_up_queries"])
    ]
```

---

## 11. Agent Lifecycle

### 11.1 Initialization

```
__init__()
  ├── super().__init__(llm_provider, model_name)    # Base: LLM client, logger
  ├── Initialize components                         # Domain-specific modules
  ├── self.graph = self._build_graph()              # Build and compile graph
  └── [Optional] self.export_graph()                # Visualization export
```

### 11.2 Execution

**Task/Research agents** (single invocation):

```python
async def run(self, user_message: str, context: dict = None, config: RunnableConfig = None) -> str:
    initial_state = self._build_initial_state(user_message, context)
    result = await self.graph.ainvoke(initial_state, config=config)
    return self._format_result(result)
```

**Conversation agents** (multi-turn):

```python
def run(self, user_message: str, ...) -> str:
    response = self.start_conversation("user", user_message)
    return response.message
```

### 11.3 Configuration Pattern

Agent configuration SHOULD use a dedicated Pydantic config model:

```python
class MyAgentConfig(BaseModel):
    llm_provider: str = "openai"
    model_name: str | None = None
    temperature: float = 0.7
    max_tokens: int = 1000
    # Domain-specific
    max_iterations: int = 3
    enable_feature_x: bool = False

class MyAgent(BaseGraphicAgent):
    def __init__(self, config: MyAgentConfig):
        super().__init__(llm_provider=config.llm_provider, model_name=config.model_name)
        self.config = config
        self.graph = self._build_graph()
```

---

## 12. Structured LLM Output

### 12.1 Instructor Integration

Agents use `BaseLLMClient.structured_completion()` for typed LLM outputs:

```python
result: SearchQueryList = self.llm_client.structured_completion(
    messages=[{"role": "user", "content": prompt}],
    response_model=SearchQueryList,
    temperature=0.7,
    max_tokens=1000,
)
```

### 12.2 Response Model Conventions

Structured output models MUST be Pydantic `BaseModel` with `Field` descriptions:

```python
class Reflection(BaseModel):
    is_sufficient: bool = Field(description="Whether gathered info is sufficient")
    knowledge_gap: str = Field(description="Summary of missing information")
    follow_up_queries: list[str] = Field(description="Follow-up search queries")
```

### 12.3 Fallback Strategy

Structured completion SHOULD include fallback handling:

```python
try:
    result = self.llm_client.structured_completion(
        messages=messages,
        response_model=ExpectedModel,
        temperature=temperature,
    )
except Exception as e:
    logger.error(f"Structured completion failed: {e}")
    result = ExpectedModel(...)  # Safe defaults
```

---

## 13. Tool Integration

### 13.1 Direct Tool Invocation

In pragmatic mode, agents invoke tools directly within nodes:

```python
async def _web_search_node(self, state: SearchState, config: RunnableConfig) -> dict:
    omnisearch = WizSearch(config=WizSearchConfig(...))
    result = await omnisearch.search(query=state["search_query"])
    return {"search_results": result}
```

### 13.2 Toolkit Integration via Toolify

Agents MAY use Toolify-registered toolkits:

```python
toolkit = ToolkitRegistry.create_toolkit("search", config)
tools = toolkit.get_langchain_tools()
```

### 13.3 LangChain Tool Binding

For LLM-driven tool selection, bind tools to the LLM:

```python
from langchain_core.tools import tool

@tool
def search_web(query: str) -> str:
    """Search the web for information."""
    ...

llm_with_tools = llm.bind_tools([search_web])
```

---

## 14. Observability Integration

### 14.1 Callback Configuration

All graph executions SHOULD include standard callbacks:

```python
config = RunnableConfig(
    callbacks=[
        NodeLoggingCallback(node_id="graph"),
        TokenUsageCallback(model_name=model_name, verbose=True),
    ],
)
```

### 14.2 Node-Level Logging

Nodes SHOULD log entry with identifying information:

```python
def _my_node(self, state: MyState, config: RunnableConfig) -> dict:
    logger.info("MyNode: Processing input")
    ...
    logger.info(f"MyNode: Completed with {len(results)} results")
    return {...}
```

### 14.3 Token Usage Tracking

Token usage is tracked automatically via `TokenUsageCallback`. Summary available via:

```python
agent.print_token_usage_summary()
stats = agent.get_token_usage_stats()
```

---

## 15. Error Handling

### 15.1 Node-Level Error Handling

Nodes SHOULD catch and handle domain-specific errors:

```python
async def _web_search_node(self, state: SearchState, config: RunnableConfig) -> dict:
    try:
        result = await self._perform_search(state["search_query"])
        return {"search_results": result}
    except SearchError as e:
        logger.error(f"Search failed: {e}")
        raise RuntimeError(f"Web search failed: {e}")
```

### 15.2 Graph-Level Error Handling

Agent `run()` methods MUST handle graph execution failures:

```python
async def run(self, user_message: str, **kwargs) -> str:
    try:
        result = await self.graph.ainvoke(initial_state, config=config)
        return self._format_result(result)
    except Exception as e:
        logger.error(f"Agent execution failed: {e}")
        return self._create_error_response(str(e))
```

### 15.3 Conversation Agent Error Responses

Conversation agents MUST return structured error responses:

```python
def _create_error_response(self, state: AskuraState, error: str) -> AskuraResponse:
    return AskuraResponse(
        message=f"I encountered an issue. Please try again. Error: {error}",
        session_id=state.session_id,
        is_complete=False,
        confidence=0.0,
        metadata={"error": error},
        requires_user_input=True,
    )
```

---

## 16. Extension Patterns

### 16.1 Creating a New Conversation Agent

```python
class MyConversationAgent(BaseHitlAgent):
    def __init__(self, config: MyConfig):
        super().__init__(llm_provider=config.llm_provider)
        self.config = config
        self.checkpointer = InMemorySaver()
        self.graph = self._build_graph()

    def get_state_class(self) -> Type:
        return MyState

    def _build_graph(self) -> StateGraph:
        builder = StateGraph(MyState)
        builder.add_node("analyze", self._analyze_node)
        builder.add_node("respond", self._respond_node)
        builder.add_node("review", self._review_node)
        builder.add_edge(START, "analyze")
        builder.add_edge("analyze", "respond")
        builder.add_edge("respond", "review")
        builder.add_conditional_edges("review", self._review_router, {"continue": "analyze", "end": END})
        return builder.compile(checkpointer=self.checkpointer, interrupt_before=["review"])

    def start_conversation(self, user_id, initial_message=None) -> Response: ...
    def process_user_message(self, user_id, session_id, message) -> Response: ...
```

### 16.2 Creating a New Research Agent

```python
class MyResearchAgent(BaseResearcher):
    def __init__(self, config: MyConfig):
        super().__init__(llm_provider=config.llm_provider)
        self.config = config
        self.graph = self._build_graph()

    def get_state_class(self) -> Type:
        return MyResearchState

    def _build_graph(self) -> StateGraph:
        workflow = StateGraph(MyResearchState)
        workflow.add_node("plan", self._plan_node)
        workflow.add_node("execute", self._execute_node)
        workflow.add_node("evaluate", self._evaluate_node)
        workflow.add_node("synthesize", self._synthesize_node)
        workflow.add_edge(START, "plan")
        workflow.add_conditional_edges("plan", self._dispatch, ["execute"])
        workflow.add_edge("execute", "evaluate")
        workflow.add_conditional_edges("evaluate", self._loop_or_finish, ["execute", "synthesize"])
        workflow.add_edge("synthesize", END)
        return workflow.compile()

    async def research(self, user_message, context=None, config=None) -> ResearchOutput: ...
```

### 16.3 Creating a New Task Agent

```python
class MyTaskAgent(BaseGraphicAgent):
    def __init__(self, config: MyConfig):
        super().__init__(llm_provider=config.llm_provider)
        self.config = config
        self.graph = self._build_graph()

    def get_state_class(self) -> Type:
        return MyTaskState

    def _build_graph(self) -> StateGraph:
        workflow = StateGraph(MyTaskState)
        workflow.add_node("preprocess", self._preprocess_node)
        workflow.add_node("process", self._process_node)
        workflow.add_node("postprocess", self._postprocess_node)
        workflow.add_edge(START, "preprocess")
        workflow.add_edge("preprocess", "process")
        workflow.add_edge("process", "postprocess")
        workflow.add_edge("postprocess", END)
        return workflow.compile()

    async def run(self, user_message, context=None, config=None) -> str: ...
```

---

## 17. Kernel Executor Integration

### 17.1 Wrapping Existing Agents

Existing agents can integrate with the RFC-1001 kernel executor incrementally:

```python
class MyAgent(BaseGraphicAgent):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        raw_graph = self._build_graph()

        # Wrap with kernel executor for event emission
        self._kernel = KernelExecutor(
            graph=raw_graph,
            event_store=self._event_store,
            bridge=self._bridge,
            agent_ref=self.agent_ref,
        )

    async def run(self, user_message: str, **kwargs) -> str:
        result = await self._kernel.execute(
            initial_state={"messages": [HumanMessage(content=user_message)]},
        )
        return self._format_result(result)
```

### 17.2 Execution Mode Selection

Agents declare their execution mode via configuration:

```python
class MyAgentConfig(BaseModel):
    execution_mode: ExecutionMode = ExecutionMode.PRAGMATIC
```

| Mode | Behavior |
|------|----------|
| `STRICT` | All node executions emit events; tool calls are event-mediated |
| `PRAGMATIC` | Direct execution with optional event logging |
| `SANDBOX` | No constraints; development and experimentation only |

---

## 18. Capability Declaration

Agents MAY declare capabilities for inter-agent discovery:

```python
class MySearchAgent(BaseGraphicAgent):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.graph = self._build_graph()

        self.declare_capability(Capability(
            id="search.web.query",
            version="1.0.0",
            input_schema={"type": "object", "properties": {"query": {"type": "string"}}},
            output_schema={"type": "object", "properties": {"results": {"type": "array"}}},
            side_effects=SideEffectClass.EXTERNAL,
            latency_class=LatencyClass.MEDIUM,
            determinism_class=DeterminismClass.NONDETERMINISTIC,
        ))
```

Capability invocations arrive as events and are dispatched to the agent's graph execution.

---

## 19. Relationship to Other RFCs

* **[RFC-0003](RFC-0003.md)**: LangGraph `StateGraph` implements the state transition graph. Node execution contracts align with the pure-function boundary. `@kernel_node` annotations map to determinism classifications.
* **[RFC-0005](RFC-0005.md)**: `declare_capability()` implements capability registration. Agent capabilities are discoverable via the projection-based registry.
* **[RFC-1001](RFC-1001.md)**: `KernelExecutor` wraps LangGraph execution with event emission and checkpointing. `BaseAgent` extensions provide event store, projection engine, and memory manager. Agent configuration uses `ExecutionMode` for kernel integration.

---

## 20. Open Questions

1. Should `BaseHitlAgent` enforce async execution to align with `BaseResearcher`?
2. Should phase-specific state types (`QueryState`, `WebSearchState`) be standardized as a framework pattern?
3. How should agents declare node determinism classification beyond decorator annotation?
4. Should HITL patterns support async streaming responses in addition to batch interrupt/resume?
5. How should graph versioning interact with capability versioning for deployed agents?

---

## 21. Conclusion

RFC-1002 standardizes the three Noesium agent archetypes — Conversation, Research, and Task — into a coherent implementation framework built on LangGraph. By defining consistent patterns for state management, graph construction, node execution, HITL workflows, and parallel execution, the RFC ensures that new agents can be built predictably while maintaining the flexibility required for diverse cognitive tasks. The integration points with RFC-1001's kernel executor and event system provide a clear path from pragmatic direct execution toward the full deterministic, event-sourced architecture.

> Agents define the cognitive logic as graphs; the framework provides the execution guarantees.
