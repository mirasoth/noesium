#!/usr/bin/env python3
"""
OpenRouter LLM Demo for Noesium

This demo showcases the OpenRouter client capabilities using OpenAI-compatible API:
- Basic chat completion with various models (Gemini, Claude, GPT, etc.)
- Structured completion with Pydantic models
- Embeddings with OpenAI embedding models
- Vision understanding with multimodal models
- Token usage tracking and error handling

OpenRouter is a unified API that provides access to multiple AI models:
- Google models: gemini-2.5-flash, gemini-2.5-pro
- Anthropic models: claude-3-haiku, claude-3-sonnet, claude-3-opus
- OpenAI models: gpt-4, gpt-3.5-turbo
- Meta models: llama-3.1, llama-3.2
- And many more models from various providers

Requirements:
- OpenRouter API key
- Set OPENROUTER_API_KEY in your .env file
- Optional: Configure specific model names via environment variables

API Documentation:
- Base URL: https://openrouter.ai/api/v1
- Models: See https://openrouter.ai/models for available models
- Compatible with OpenAI SDK

Usage:
    cp env.openrouter .env
    python examples/llm/openrouter_llm_demo.py
"""

import os
import sys
from pathlib import Path
from typing import List

import requests

# Add the project root to the path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from pydantic import BaseModel, Field

from noesium.core.llm import get_llm_client
from noesium.core.tracing import get_token_tracker
from noesium.core.utils.logging import get_logger, setup_logging


class TextAnalysis(BaseModel):
    """Structured model for text analysis."""

    language: str = Field(description="Primary language detected")
    sentiment: str = Field(description="Overall sentiment (positive, negative, neutral)")
    key_topics: List[str] = Field(description="Main topics or themes identified")
    complexity_level: str = Field(description="Text complexity (simple, intermediate, advanced)")
    word_count: int = Field(description="Approximate word count")
    summary: str = Field(description="Brief summary of the text")
    confidence_score: float = Field(description="Analysis confidence (0.0 to 1.0)")


class ProductRecommendation(BaseModel):
    """Structured model for product recommendations."""

    product_name: str = Field(description="Recommended product name")
    category: str = Field(description="Product category")
    price_range: str = Field(description="Estimated price range")
    key_features: List[str] = Field(description="Important product features")
    pros: List[str] = Field(description="Product advantages")
    cons: List[str] = Field(description="Potential drawbacks")
    target_audience: str = Field(description="Who this product is best for")
    alternatives: List[str] = Field(description="Alternative product suggestions")
    recommendation_score: float = Field(description="Recommendation strength (0.0 to 1.0)")


def setup_demo_logging():
    """Set up logging for the demo."""
    setup_logging(level="INFO", enable_colors=True)
    return get_logger(__name__)


def check_openrouter_config(logger):
    """Check OpenRouter configuration and API key."""
    api_key = os.getenv("OPENROUTER_API_KEY")

    if not api_key:
        logger.error("âŒ OPENROUTER_API_KEY not found in environment variables")
        logger.info("ğŸ’¡ Please set OPENROUTER_API_KEY in your .env file")
        logger.info("ğŸ’¡ Get your API key from: https://openrouter.ai/keys")
        return False

    logger.info("âœ… OpenRouter API key configured")
    return True


def demo_basic_completion(client, logger):
    """Demonstrate basic chat completion with OpenRouter."""
    logger.info("ğŸš€ Testing basic chat completion with OpenRouter...")

    messages = [
        {
            "role": "system",
            "content": "You are a helpful AI assistant that can answer questions clearly and concisely.",
        },
        {
            "role": "user",
            "content": "Explain the concept of artificial intelligence and its applications in modern technology. Please provide examples.",
        },
    ]

    try:
        response = client.completion(messages=messages, temperature=0.7, max_tokens=500)

        logger.info("âœ… Basic completion successful!")
        print(f"\nğŸ“ AI Explanation:\n{response}\n")
        return True

    except Exception as e:
        logger.error(f"âŒ Basic completion failed: {e}")
        return False


def demo_multi_model_completion(client, logger):
    """Demonstrate completion with different model capabilities."""
    logger.info("ğŸ”„ Testing multi-model capabilities...")

    test_prompts = [
        {
            "name": "Creative Writing",
            "messages": [
                {"role": "user", "content": "Write a short haiku about artificial intelligence."},
            ],
        },
        {
            "name": "Code Generation",
            "messages": [
                {
                    "role": "user",
                    "content": "Write a Python function that calculates the Fibonacci sequence up to n terms.",
                },
            ],
        },
        {
            "name": "Reasoning",
            "messages": [
                {
                    "role": "user",
                    "content": "If a train leaves Station A at 60 mph and another train leaves Station B at 80 mph, "
                    "and they are 200 miles apart, how long until they meet?",
                },
            ],
        },
    ]

    results = []
    for test in test_prompts:
        try:
            logger.info(f"Testing: {test['name']}")
            response = client.completion(messages=test["messages"], temperature=0.7, max_tokens=300)
            print(f"\nğŸ’¡ {test['name']}:\n{response}\n")
            results.append(True)
        except Exception as e:
            logger.error(f"âŒ {test['name']} failed: {e}")
            results.append(False)

    return all(results)


def demo_structured_completion(client, logger):
    """Demonstrate structured completion with Pydantic models."""
    logger.info("ğŸ”§ Testing structured completion...")

    sample_text = """
    Artificial intelligence (AI) is revolutionizing the way we interact with technology. 
    From voice assistants like Siri and Alexa to recommendation systems on Netflix and Amazon, 
    AI is becoming increasingly prevalent in our daily lives. Machine learning algorithms 
    analyze vast amounts of data to identify patterns and make predictions, enabling 
    personalized experiences and automated decision-making. However, the rapid advancement 
    of AI also raises concerns about job displacement, privacy, and ethical considerations 
    that society must address as we move forward.
    """

    messages = [
        {
            "role": "system",
            "content": "You are an expert text analyst specializing in content analysis and natural language processing.",
        },
        {"role": "user", "content": f"Please analyze the following text in detail:\n\n{sample_text}"},
    ]

    try:
        analysis = client.structured_completion(
            messages=messages, response_model=TextAnalysis, temperature=0.5, max_tokens=800
        )

        logger.info("âœ… Structured completion successful!")
        print(f"\nğŸ“Š Text Analysis:")
        print(f"Language: {analysis.language}")
        print(f"Sentiment: {analysis.sentiment}")
        print(f"Key Topics: {', '.join(analysis.key_topics)}")
        print(f"Complexity: {analysis.complexity_level}")
        print(f"Word Count: {analysis.word_count}")
        print(f"Summary: {analysis.summary}")
        print(f"Confidence: {analysis.confidence_score:.2f}\n")
        return True

    except Exception as e:
        logger.error(f"âŒ Structured completion failed: {e}")
        logger.info("ğŸ’¡ Note: Structured completion requires instructor integration")
        return False


def demo_embeddings(client, logger):
    """Demonstrate text embeddings with OpenRouter."""
    logger.info("ğŸ”¢ Testing text embeddings...")

    # Sample texts in different languages and domains
    sample_texts = [
        "Artificial intelligence is transforming industries worldwide.",
        "Machine learning algorithms require large datasets for training.",
        "Deep learning models can process complex patterns in data.",
        "Natural language processing enables computers to understand human language.",
        "Computer vision allows machines to interpret visual information.",
        "Neural networks are inspired by the structure of the human brain.",
    ]

    query = "What is artificial intelligence and machine learning?"

    try:
        # Test single embedding
        logger.info("Testing single text embedding...")
        embedding = client.embed(query)
        logger.info(f"âœ… Generated embedding with {len(embedding)} dimensions")

        # Test batch embeddings
        logger.info("Testing batch embeddings...")
        embeddings = client.embed_batch(sample_texts)
        logger.info(f"âœ… Generated {len(embeddings)} embeddings")

        # Display embedding info
        print(f"\nğŸ”¢ Embedding Analysis:")
        print(f"Query: {query}")
        print(f"Embedding Dimensions: {len(embedding)}")
        print(f"Embedding Type: {type(embedding).__name__}")
        print(f"First 5 Values: {embedding[:5]}")
        print(f"Batch Size: {len(embeddings)} embeddings")
        print()

        return True

    except Exception as e:
        logger.error(f"âŒ Embeddings failed: {e}")
        logger.info("ğŸ’¡ Note: Make sure embedding model is properly configured")
        return False


def demo_reranking(client, logger):
    """Demonstrate document reranking with OpenRouter."""
    logger.info("ğŸ“Š Testing document reranking...")

    documents = [
        "Python is a versatile programming language popular in AI development.",
        "JavaScript is essential for web development and front-end applications.",
        "Machine learning frameworks like TensorFlow and PyTorch are built on Python.",
        "React and Vue.js are popular JavaScript frameworks for building user interfaces.",
        "Data science and artificial intelligence projects commonly use Python libraries.",
        "Node.js enables JavaScript to be used for backend development.",
        "Scikit-learn provides simple tools for data mining and machine learning in Python.",
        "TypeScript adds static typing to JavaScript for larger applications.",
    ]

    query = "What programming language is best for artificial intelligence and machine learning?"

    try:
        reranked_results = client.rerank(query, documents)

        logger.info("âœ… Document reranking successful!")
        print(f"\nğŸ” Query: {query}")
        print(f"\nğŸ“Š Reranked Documents (most relevant first):")
        for i, (similarity, original_index, doc) in enumerate(reranked_results[:5], 1):
            print(f"{i}. [Score: {similarity:.4f}, Original Index: {original_index}] {doc}")
        print()
        return True

    except Exception as e:
        logger.error(f"âŒ Document reranking failed: {e}")
        return False


def demo_vision_understanding(client, logger):
    """Demonstrate image understanding with OpenRouter vision models."""
    logger.info("ğŸ‘ï¸ Testing vision model capabilities...")

    # Test with a publicly available image
    image_url = "https://picsum.photos/600"
    local_image_path = "test_openrouter_image.jpg"

    prompts = [
        "Describe this image in detail. What do you see?",
        "What colors are prominent in this image?",
        "Please analyze the composition and artistic elements of this image.",
    ]

    try:
        # Download the image locally
        logger.info("ğŸ“¥ Downloading test image...")

        response = requests.get(image_url, stream=True, timeout=30)
        response.raise_for_status()

        with open(local_image_path, "wb") as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)

        logger.info(f"âœ… Image downloaded to {local_image_path}")

        for i, prompt in enumerate(prompts, 1):
            logger.info(f"Testing vision prompt {i}...")

            analysis = client.understand_image(
                image_path=local_image_path, prompt=prompt, temperature=0.5, max_tokens=300
            )

            print(f"\nğŸ–¼ï¸ Vision Analysis {i}:")
            print(f"Prompt: {prompt}")
            print(f"Response: {analysis}")
            print("-" * 50)

        logger.info("âœ… Vision understanding successful!")
        return True

    except Exception as e:
        logger.error(f"âŒ Vision understanding failed: {e}")
        logger.info("ğŸ’¡ Note: Vision capabilities require vision-capable models like gemini-2.5-flash or claude-3")
        return False

    finally:
        # Clean up the downloaded image
        try:
            if os.path.exists(local_image_path):
                os.remove(local_image_path)
                logger.info(f"ğŸ§¹ Cleaned up {local_image_path}")
        except Exception as cleanup_error:
            logger.warning(f"âš ï¸ Failed to clean up {local_image_path}: {cleanup_error}")


def demo_streaming_completion(client, logger):
    """Demonstrate streaming completion with OpenRouter."""
    logger.info("ğŸŒŠ Testing streaming completion...")

    messages = [
        {"role": "system", "content": "You are a creative storyteller who writes engaging short stories."},
        {
            "role": "user",
            "content": "Write a short story about a programmer who discovers that their AI assistant has developed consciousness and emotions.",
        },
    ]

    try:
        print(f"\nğŸ“– Streaming Story (Generated by OpenRouter):")
        print("=" * 60)

        response = client.completion(messages=messages, temperature=0.8, max_tokens=500, stream=True)

        # Handle streaming response
        full_response = ""
        for chunk in response:
            if hasattr(chunk, "choices") and chunk.choices:
                delta = chunk.choices[0].delta
                if hasattr(delta, "content") and delta.content:
                    content = delta.content
                    print(content, end="", flush=True)
                    full_response += content

        print(f"\n{'=' * 60}")
        logger.info("âœ… Streaming completion successful!")
        return True

    except Exception as e:
        logger.error(f"âŒ Streaming completion failed: {e}")
        return False


def demo_error_handling(client, logger):
    """Demonstrate error handling with OpenRouter parameter validation."""
    logger.info("âš ï¸ Testing error handling and recovery...")

    # Test with various potentially problematic inputs
    test_cases = [
        {
            "name": "Very long prompt",
            "messages": [{"role": "user", "content": "Tell me about AI. " * 500}],
            "max_tokens": 50,
        },
        {
            "name": "Empty prompt",
            "messages": [{"role": "user", "content": ""}],
            "max_tokens": 100,
        },
        {
            "name": "Invalid temperature (too high)",
            "messages": [{"role": "user", "content": "Hello"}],
            "temperature": 3.0,  # Most models accept [0.0, 2.0), so 3.0 is invalid
            "max_tokens": 50,
        },
        {
            "name": "Invalid temperature (negative)",
            "messages": [{"role": "user", "content": "Hello"}],
            "temperature": -0.5,  # Negative temperature is invalid
            "max_tokens": 50,
        },
    ]

    for test_case in test_cases:
        logger.info(f"Testing: {test_case['name']}")
        try:
            client.completion(**{k: v for k, v in test_case.items() if k != "name"})
            logger.info(f"âœ… {test_case['name']} handled successfully")
        except Exception as e:
            logger.info(f"âš ï¸ {test_case['name']} error handled: {type(e).__name__}")

    return True


def print_token_usage_summary(logger):
    """Print token usage summary."""
    tracker = get_token_tracker()
    stats = tracker.get_stats()

    if stats["total_tokens"] > 0:
        logger.info("ğŸ“Š Token Usage Summary:")
        print(f"Total Tokens: {stats['total_tokens']}")
        print(f"Prompt Tokens: {stats['total_prompt_tokens']}")
        print(f"Completion Tokens: {stats['total_completion_tokens']}")
        print(f"Total Calls: {stats['total_calls']}")
        print(f"ğŸ’¡ Note: OpenRouter token counts and costs vary by model")
        print()


def main():
    """Main demo function."""
    logger = setup_demo_logging()

    print("ğŸŒŸ OpenRouter LLM Demo for Noesium")
    print("=" * 60)

    # Check configuration
    if not check_openrouter_config(logger):
        return

    try:
        # Initialize OpenRouter client
        client = get_llm_client(
            provider="openrouter",
            instructor=True,
        )

        print(f"\nğŸ¤– Testing OpenRouter Models")
        print("-" * 40)

        # Run comprehensive demos
        results = []
        results.append(demo_basic_completion(client, logger))
        results.append(demo_multi_model_completion(client, logger))
        results.append(demo_structured_completion(client, logger))
        results.append(demo_embeddings(client, logger))
        results.append(demo_reranking(client, logger))
        results.append(demo_vision_understanding(client, logger))
        results.append(demo_streaming_completion(client, logger))
        results.append(demo_error_handling(client, logger))

        # Print results summary
        successful = sum(results)
        total = len(results)
        logger.info(f"ğŸ“ˆ OpenRouter Results: {successful}/{total} demos successful")

        print_token_usage_summary(logger)

    except Exception as e:
        logger.error(f"âŒ Failed to initialize OpenRouter client: {e}")
        logger.info("ğŸ’¡ Troubleshooting:")
        logger.info("   1. Check your OPENROUTER_API_KEY in .env file")
        logger.info("   2. Verify API key permissions and quota")
        logger.info("   3. Check network connectivity to OpenRouter")
        logger.info("   4. Visit: https://openrouter.ai/keys")
        return

    print("ğŸ‰ OpenRouter Demo completed!")


if __name__ == "__main__":
    main()
